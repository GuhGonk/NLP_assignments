{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"elapsed":1038,"status":"ok","timestamp":1702263053788,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"qwPi_9zLwYb8","outputId":"47d4634f-0675-4573-e320-4d87329d6fc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXYAAAC4CAYAAAD3y8cVAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAACdLSURBVHhe7Z0HnBRF2v//cOopHAZAhINXwBcReOUv4CmoBBU5FUHFw78oAoZTVMSTMwF6CgoKGF8MiCBZQRCBJS0Lu7DEJW1i2Zxzzjk9/36KHnYdit2dnurZ3vH39fN8ZMLWU9Pd9e3qmp6q/0MAAADcCogdAADcDIgdAADcDIgdAADcDIgdAADcDIgdAADcDIgdAADcDIgdAADcDIgdAADcDIgdAADcDIjd4pSXl1NRURFVV1frzwAAQMNA7Bbnk08+ob59+9LRo0f1ZwAAoGEgdosDsQMAHEWp2Kuqqmj37t20ZcsWEStWrKAjR45QaWmp/o7mJysri7Zt20b79++n1atX08qVK+nw4cP6q9ajJYg9LS1N7GuOvXv3iuEjAEDzoVTsLPDhw4dT//79aebMmTRhwgR64IEH6NChQ5YZIz558iQNHDhQ1Gv27Nk0adIkGjp0KIWEhOjvsBZWF3t+fj49//zzNHr0aJo6dSqNHDlSyB0A0HwoF/uIESPooYceooyMDAoICBCPFyxYQMXFxfq7mheb2N9++20qKyujuLg46tGjB3366af6O6yF1cW+fft2at26tbjqiYmJobFjx9Ibb7xhqas0AP5oKBf7PffcQ1OmTBGPExISREPn3jv37KyATew8BMNDR1znPn360DvvvKO/w1pYXexz5syhVq1aiZ46R9euXcVVUHp6uv4OAICrMVXsoaGhdN9991la7CUlJXT11VdD7Ab58ssvRY+dr85sER8fT5WVlfo7AACuRrnYebz6jjvuEJfl69evp+7du5OHhwfV1tbq72pebGKfOHGiGB7iOnbu3Jk8PT31d1gLq4udvxxnsa9ater847Vr14p/AwDOkZeXR3PnzqWOHTuK2LBhg6mdH1N67N26daPLL79cxKJFi8TzVsEm9p49e1KbNm2oXbt24m4Oq8Jj/wMGDCA/Pz/9GevBB6ltf/MwDACgjoqKCvrxxx9p8ODBooPGV7l8g0lkZKT+DvWYOhRjReyHYgAAwEwyMzOFE/mmEn9/f9GR5Bs2du3aRTU1Nfq71AKxAwCAifDvPMaNG0ddunQRdwnawsvLq2WInS855s+fT99//73+jPXgsX++f93X1xfzrwAATCc3N5dmzJhB48ePF713hm8yMPMWcKViBwAA8Hu4w8vDLmPGjKGXX35Z/K5nyZIl4gtVs4DYAQDAZLh37u3tTYsXLxbBv/ExE4gdAADcDIgdAADcDIi9mSkvr6TwqFQ6cPgs7dkfRHt8mh5e+4Pp4NFQiolLp4pK8+7wqa6uodj4DPI+GCKtR2PhpcX+QyGUkVmglwiA+1FUXEb+wXG090CwtB00Fvx3/kGxVFhUppdoHENiZ4lEx6bTPt8z5OF5mrbtPuVQeO4LpMCQeCopNW96V97IJ/yjyNM7UFqHxmKnVwAdOxlJuXlFeonqKa+oFDvSyDa0j9CIZKqqMucun9j4TPKQ5HQ0dmv7Iiu7UC8VAPehpKScTvrHSI97R4PL4fKcwWGxV2pSD9Mksl2BjPxORZki9/yCYsNCtw+Wbk6uOXJPTs3ReunB0ryOhrdviCn15Kkgdu0LkOZ0NDw8T9GxU+b92g6A5iIxJZt2ePlLj3tHg8tJSsnRSzaGw2LPzS8WPXVZhRwNT+8gSkjK0ktWh39QnJJesC2OHI/QS1YLX/WoqiefaNMz1E+0xmJX0Vu3xWG/cL1kANwH9pjseDcaznrRYbFnZhco6a1zsNQiolL1ktXhezRUms9o7NoboJeslsiYNGk+o5GWrv6+WBa7LJfROASxAzckvqWLPSOrQFoRoxEWmaKXrI79h89KcxkNvjQyA4gdAPcAYrcLiF2e00hA7AA0DxC7XUDs8pxGAmIHoHmA2O0CYpfnNBIQOwDNA8RuFxC7PKeRgNgBaB4gdruA2OU5jQTEDkDzALHbBcQuz2kkIHYAmgeI3S4gdnlOIwGxA9A8QOx2AbHLcxoJiB2A5gFitwuIXZ7TSEDsADQPELtdQOzynEYCYgegeYDY7QJil+c0EhA7AM0DxG4XZohd9SRgu/eZMwkYZncEwD1gEcuOd6PhcrGL2R33KJzdMVr97I6nAtQsXmELs6btTUzOVjZv/N4DZyg7x5z52Hco29+nxOIlALgb3JZVzXrL7S0pJVsv2RgOiz03r5j2aRKRVcjR8PQxZz52Xmhj1z41wuTIzDJn1Z+y8go6GaBm1ZWQsETTlseL0q4sZDkdDb7ySUvP1UsFwH3gFduOn46WHveOht+pSK28Ur1kYzgsdl5+LTImVYw7cw9MVjGOrbtOipC9xrF9jz+dCowRcjOD3LwSOuIXIZZj4xWAZOHheZK++uYnrT4npK8fPBpuyrh1fUrLyulseDJ5+57Rcl5Y1x1ep2nFmh308yYf2rnX/3ev7dbez98nRMWmiWX2zKKquoYio1PIa3+QkHP9Othis8cR+nbpRm2/nrrgNf6bfb7BlAqpAzemoLCETvpHi6tw+zbAwW35R60tr1m/h3Zq/rR/nf/uZEC0KMdZHBY7w8vjcU+bL6t5EWaWS/3gRrxy7Q5asmwT7fEJuOB1HmcNj0rRpGaO1JtCZWUlrV+/nq644gpatmwZlZebt/6qUWpqaigwMJBGjRpFzz33HCUkJIihEavB2+7jjz+mXr16kZeXl3byN29hbQBaItyWg4KCaPTo0TR58mSKjY01tS0bEntD8AeIiIigJ598kkaMGEEHDx60ZEMPDQ2l4cOHU+vWrenee+8lf39z7nxxhpycHJo3bx5de+211L17d1q1ahVVVDTfyfBinDx5kvr27Utt2rQ5fwICANSRl5dHCxYsoE6dOlHXrl1pxYoVVFrq3HBLQygXO1d29erV1Lt3b+rWrRvNnz+fsrLUj6M7y5kzZ2j79u305z//Wfyfe8ZWIzs7m3x8fMRZfvbs2eTt7S2uNKzG8ePHxVUPy33Pnj0QOwB2sNi5/U6YMIGmT59Ovr6+LUvsfFnOvd+33nqLpkyZQkePHqX8fPW34amCe5lWZ9q0abR161b9kTWJi4ujoUOH6o8AADI++OADWr58uf7IPJSL3QZXnj+E1YHY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOBC7i4DY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOBC7i4DY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOBC7i4DY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOBC7i4DY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOBC7i4DY1QCxA9A4ELuLgNjVALED0DgQu4uA2NUAsQPQOJYVe632X0FlMoXlb6YTWQvoWMa7Wsy6IJb7PExfbL1H8tpsOp75IZ3JXUsZZWepprZaL1kttbU1lFTiR/7ZS8kvc66kHudi4n/aSZ/nv/HP/o7iiw6aVkemhqopvewMBeeu1nLOkdbl4w1DaN3RJySvzdb2wScUmr+R8iritT1To5eqlnP7PJH8c5ZodXxfUo9ZtCdqGs34+r+lr3HwZzub9wtV1JTopbo3vF9TSwMoMHfFRbdZw/Euncz6jCIKtlFxFa8ZbM6K9qXVORRVuJtOZX1Jfhn/kdSj4TieOV87dtdSZlmoaccfU11bSbFF++l09jfa9nxPWpeLhvb+09n/S9GFe6iyxrx1Rmu0OiYUH9T22yItr9yL7ER2o+w12z5PLjkuPq8zOCR2buDZ5eHklTKdfo4ZQj9GdKFl4ddocbVDsTziWloT1Z+2Jz5NMYWeysXJUj+RtZi2xI+jlZH/reXseEEdGo+O2t/2pF/jH9I2+EJT5M6NP6pwu7YdJmnb439oucP1vEbbB53pp+i/0e7kF7QTRKApjauwMoF2JP5D2x43aDk72NWhqdGR1kX317bl+24vd96vYdrJ1iPxSVod1Uf77Ea2Ge/brrQ+5i7am/oaFVWl6aWro6gylfanzaJfYkfQioj/0nK2t6tD47E8/Drt2L2ZdiRN0cS525TjjyV3JGM+/Ro3WjsGe2h5Ha3nNbQi8nrtc47UPu9Mqqot10tWR01tlXYS/oU2xg7X9ttfRU55XRqKc/t8c9w9FKttSy7TKA6Jvaw6nw5lzKOVETdqO9RoA7cFf4jraWfyc5RZHqZnUENckS/9FDNUq2MnSV7Hgk9Ca6Nvo4jCnXrp6sgoP0s7k54R28HYgWCL9tqBewN5awdtiejdqYMb6p6UV0QOeW7HYk1UbwrMWaGX7p6klvrTtoQJ2n7tpn1mZ/YrRwdt395ERzI/VypNlttp7Wp2VWQ/Ax0K+zgnzl3Jz2ttOVTPoI6wQg/tuLnV6fbMn3Ol1oEK0K6OVZOi9bJ/jRup5XF2f3Nco8n9QcrSroKM4pDY87XL/XXRQ7TEaho5f4DV2oaOVizNvSmva43qOkk+Y8Fy35X0gl66OkLzNtDqSO7RqTgY2msnoL9RTnmkXroa+Erl3IlHltNIdCCf1Ff00t2TgJwfNGH20j6riv3K0V7rqAzXrkTVXTWWV+dpPdhRomx5TkeD23I/caWimh1Jz2pSvlaS00i0p18TxuklqyM8f71Wx86SfMZiuXYlnlxyQC/dcRwSe67Ws5ZVwtkIz1d7Bv0t/h6tXFWN6lxsjL1VL10dgTlfSHM5E1llAXrpauDLQVkeZ8I75Tm9dPeEx4Bln9vZcObS3J7S6kxNHs5f0doHH9Oq4bYny2U01kT11EtWBztMlsuZSCr21kt3HLcU++a4u6R5nIlfIHZlAbEbC6Vir8qU5nA2zBA7tz1ZLqMBsdsBsasFYndPIHa1QOyOA7E3MSB2dQGxGwuIXU1A7HZYWey5ubkUHx9PZWVllhV7bW0txcbGUkZGhnhsVbGnp6dTQkICVVdXQ+wGsLLYeb8mJiZaWuwFBQWiLRcXF4vHVhV7TEwMpaWduw0VYpeECrGHhITQzJkzaf369bT27EBpHmdChdhZlPyrs7feeouio6MtK/aDBw/Syy+/TN7e3hC7Aawsdg8PD5o4cSIdOr5bmsPZUCH2qKgoev/992nlypVC8lYV+5o1a+jVV1+lsLAwiF0Wb342TBxszsTo0aOpc+fO1Lt3b1q4V92tjrZYfLSrNK8j8dRTT9HAgQPpyiuvpJdeeom2nJouzWU0Zm64mia9OEaa25EYOXIktWvXTtTV19dHmsuZgNiNxdOTnpTuL0di2LBh1Lp1axpx3yBpDmdj1neDpXkdibFjx1K3bt3ohhtuoB9//JFWn+0nzWU0XvriWmleR+O2226jtm3b0qRJk8jjxLvSXM5Eixc7b5QDBw44FXwADBgwgO6++2760pd/RSfPZTRWne0rzetI+Pj40NSpU+m6666jzz//nA7GzZHmMhpfHL2adh74UZrbkfjyyy+pS5cu9Nhjj1FScoI0lzMBsRuLA77e0v3lSMydO1eI/ZkXx0tzOBtbTk6X5nUk1q5dS3feeSfdcccdWsfCl36OvEWay2h85tNNmtfReP311+nqq6+mDz/8kI7F/a80lzOBoRiN4OBg+vrrrykgIIA2ih9RyXMZDVVDMXx5yZdwRUVFFJBtzaEYPmi/+OILSkpKwlCMAaw8FLNlyxZatGgRpWRFSHM4GyqGYiIiIujbb78lPz8/qqys1Nqe2qsLVUMxq1evpmXLllFhYSGF5a2S5nImIHYN/mKSxcn/t/JdMeILyZpzPw236hg714/rKf4NsTuMlcVu27dW/vK0fltmrDrGXr8tY4xdEirEXh/c7qgOiN1xrCx2G7jdUS0QuyQgdnUBsTc/ELtaIHbHgdibGBC7uoDYjQXEriYgdjvyKiL1qUjlFTESyyOu0zbKz3oGNbQUsQflfic+vyyfkeB5oLPLgvXS1XBO7KpmADwX7i72E1kfK59gi9vdH1Xsv8apndRvXfT/1UtWR3j+Gq1stRMPukzshZXJtCl+jNPzItdFB/opZjDFFRn/ADI8EsdpZauU0TX0W/z9eunqiCzcrn3+27XynZ3bnk+QHemXuJHayTdWL10NPFXs6qj+0pxGgoXnm/6GXrp7cjZvPa2N5h/JqTkGedroX+MfoVpSN21vWXU2rYrsLc1nNLhjEZy7VM+gDu+0t5V1KLkjtSPpeb1kdUQW/EYrxCIg8ryOBpeVUnJYL91xHBI7LyvFS32tjLxJS+7s/Mi80MZ/0X5tp6leHeZY1uf6ykmyvI4Hz0d+MONDvXR1FFSm0L5UnjveyKow9YMX2uhJp7K/oYqaIr10NfCqWQHZS0UOee6mxw/hf6ENMYMo0YkDtiWQV5lAu5P/qe3X7trndrYX10E7lntTeAGveatueTw+TnYkP6+JjldBk+V1NDrQhthhFFPkpWdQR1ppoHaivN3punLnZ2VUP+34O6aXrA7uUHkmT9byOLu/rxThk/aq5sVUvXTHcUjsfGDxCj3+OT/QL7H3ahvK6MTyHbTLoVvpsCbL3IporVS1y2nxmqwbY0cLIcvzNz2WR3TVetUjKLdSbU+Y4c/NSw0eSP8PrY0aoOVzXJ7cA9kQO0KT+rfagZAuSlVNWXUencz+glZF8QldXo+mxIbY4RRfvNfp9RytDu/XzLIQ0dNcHXWzdFs0JbgHvCn+QQrJ+1n5CZsXUIkr8tGOu7850Y5twR2LG7UrsffEGqqq4aUGE4p9aVvi07Qioqckf+PBLtiS+DjFFO5ROqRlg5fjzCwL0k7oz4r9JqtDU4KvTLxTp1NORYRTXnRQ7Eyt1nMvocLKJDHmnlcRfkHEZx6n/3zyIj3zymgKjt4rfU9+RRyVV+drpZmxSG+tliNO6w3P1Ho7xn+OvDKyL+1JnaFt5EiT6sk1rRXi5O0h206h8ftp8kv307vz/ym264XviRALTVfU8IRJ5tSRy+Xy8ytiJPnDz32p/tM8Gnb/TXTYf7P0PRx8zJjRqKwIN0qWXL7Wk5NtC44jAb/RvWP+h1ZtXCi24YXviRTDn2as0clwuSz3bQkTnegE8XDqMDqhXS0Wm9SxYHh7cvl5Wkfwwu0UTp4H11DvAVfRbt9V0tfzKqLEyICZC9NzHUuqMrVcci9yW/7na2PpnbnPUGz6Mel7uJ583DgjdcaA2BumoqKCfvnlF2rfvj21adOG5s+fLybyaQ6qayu0k1CxFoXSOHjEi9p3akvbd22Svs5/a1ajagr869SPPvqI/vKXv4j5ZXi7VlVZT4w8aRP/tPqSSy6hxx9/nDIzM/VXwMXgGTSfeOIJuvTSS6lDhw5iIqnmgAVSVVOmHetFdsf+ucjKS6Y5H82kx598mCJjgqXv4Y4er9DfXPBMkIMGDaJWrVpRr169xGOrwW2Zf/HLTuR5mNatWydcaRbKxc4S55/a8jwj9957L33zzTfip+lWIy4ujvr06SMOhv79+zdbw2oInmL1hx9+oCFDhoiJhr7//nsxLbHV2LRpk5iErWPHjjRjxgwKDAzUXwEXw9/fn7766ivq3r27mO1zw4YN+ivWgTsRGzduFCK6/PLLadasWZSfn6+/ah327dsnpMknyYULF5Knp6f+inVISUkR7ZedyG60zVxpFsrFboOnp/3ggw/0R9bj0KFD9N1339Fll11GS5Ysof379+uvWI9p06bR1q385Zl14RPl0KFD9UegqfA2421nRcrLy8VV4osvvkjDhw8XvUwrdtJscG/Y6rAT2Y1m84cVu42WcDBA7O6LlcVug489PgatDsReB8QOsSsBYjcGxK4OiL0OiB1iVwLEbgyIXR0Qex0QO8SuBIjdGBC7OiD2OiB2iF0JELsxIHZ1QOx1QOwQuxIgdmNA7OqA2OuA2CF2JUDsxoDY1QGx1wGxQ+xKgNiNAbGrA2KvA2KH2JUAsRsDYlcHxF4HxA6xKwFiNwbErg6IvQ6IHWJXAsRuDIhdHRB7HRA7xK4EiN0YELs6IPY6IHaIXQkQuzEgdnVA7HVA7BC7EiB2Y0Ds6oDY64DYIXYlQOzGgNjVAbHXAbFD7EqA2I0BsasDYq8DYofYlQCxGwNiVwfEXgfEDrErAWI3BsSuDoi9DkNir62tpbLySsovKKHcvGJprF6znhZ9+pX0tbz8YiopKaeaGudW4m4ILruouEzLdfE6ctwy4Dbp81xH/vuqahNXNde3Y0Fhw3Wc/d4c2uqxS/oa/y2XwWWZBRfNOXibyOrAcTY0iv7fE09LX7MFb08z97nV4M9aXFze4HbjbcbbTvYat6/yCvP2LZdaWVlFhUWllNtAHfnY42NQ9hq3r5JS89tycYnxtsyfrbBIa8tV5rVlplp3TkPbkp3IbpS9xsH7XEV7dljsnJAPVP/gOPL0DiIPz1O0bbdjsXNvAB09EUlpGXmmHBC8A+OTsujgsVDapeWS1aGx2LHHnw4cOUuRMammHBA1NbWUk1sktqPX/mBtO56W1qOh4L/hv+UycvOKTBMANwrOsdPLX1qPpgTX9dCxcEpKyabqaveXO3/G5NQcOuQXrh1LxvbtHp8gCjqbIGRhxq5lIYdGJJP3wRDarh3vsno0Fty+jp2KpJS0XFP2K5eZmJytbccww22ZP9v+w2cpPCqFKiqq9JLVwvVMTcvTnBOm5XN8f9ti975A8g+KE451pj07LPbSsgqR2IiI7IMbOp/dVMMNyuhBYB/8OeMTM/WS1cGN9YR/tFa+PK+jcSogRjRU1fCxdTowVprTSOzzPUOZWeatzm4V+DOyMGXbwNEICUtS3rlgEbHUtytoxxwszuycQr10dXDnj09wspxGIiYuXS9ZLdxJ8z0SKs1pJE4HxQrXGsVhsfMH8FS0oVm+sfEZesnqOH6ahanmgOXgg1Y1fMDu9g6U5jMSfPWUma2+YXGvga9eZDmNBJfFonJ3+DOq2m58VVZWVqmXrAbuue49ECzNZyT4ai4iKlUvXR3ciXSmB2wf3r4heslq4asKVSdJDnYsu9YoDoudeyKqepkeWvDlkWoOKDxzcuzc66+XrI6klBxl25GDy+KThWpY7LJ8zgRfAbg7Kq9yuJNSUmq89yaDx+5Vdn44gkMT9dLVwUO2slxGgz+zGfDQryyf0eD27MyVrcNiz9CSySpiNMIi1Yude9iyXEZjh9YbUQ2PNctyORNp6S1D7Kf+AGLnzyj77EbDDLHL8jgTwWcT9NLVceREhDSXM2EGqsXOwa41CsTehIDY5fmMBsTueEDs6sIMIHa7gNjVBcRuHSB2NUDsxoDYmxAQuzyf0YDYHQ+IXV2YAcRuFxC7uoDYrQPErgaI3RgQexMCYpfnMxoQu+MBsasLM4DY7QJiVxcQu3WA2NUAsRsDYm9CQOzyfEYDYnc8IHZ1YQYQu11A7OoCYrcOELsaIHZjQOxNCIhdns9oQOyOB8SuLswAYrcLiF1dQOzWAWJXA8RuDIi9CQGxy/MZDYjd8YDY1YUZQOx2YcYkYIeOhUlzGY093oF6yergqYWNzNN9seCZBNMz8/XS1cFi58naZDmNBE/CFBBs7RWDVGB9sVc5Nb++ffDMhmdNmLXz+KkoMSGWLKeR4BllzSBBE7vKdsLtOcuJ2VodFjsnU3VAsNiiYtL0ktXBU6aqnOrzdJB6EWXnFNH+Q+quLHhGS15hRjUsdpXTu/JUxTEmTNVsNQLPxCubPZFl5Mzc3DIqq6qV9oZ5zvSEpGy9dHWER6WKhXlkOY3ESf8YvWS18EIju/epq6fv0TAqKCzVS3cch8XOy2gd9guXVsbR4IUIzJhqlhecOHIi0ukDYqdXAB04HKpt4DK9ZHXwwgnRcemaNM84NY8z/y2LNzouw7Slv/jqguvprKhYUKcCYqlUce/TisQnZilbt4DXF6ioVLvyD5+wM7LyyUfrXDg7b7yndrIO0E5kqueMZ/iExp/f2YVzeDiVh2jz8tR3fhiu55mwRLECkix/U4PbGLfn2PhMrT0bX5HKYbHzun7JaTnijGJUnNxTZ6lHar11XnPRDHitSZ74PzAkXhx0RoLH/83oBduoqKzWpJlLZ0ITRQ9PVofGgv+WyzBryS+G9zn3SHiZNlkdmhL8+Xh/F5eoX+XJivD+CNEautETN1/Ws8y4E5WZXSBErBpenpGvwM+GJxs+/rh9sYRUDxXVp6SkgiKj05xryxEplJPLy83phZoAdyijY9OdqqetPTvrRYfFzvCyWtm5ReKSmuXJ4+RNj1SKik2jdK2nbpbUAbAC/AUlnxD5hCZvCxePiOhUik3IoLyCYiFgABzBkNgBAABYF4gdKCE9PZ3Gjx9PGzZs0J8BANQnNzeXPv/8c5o3b55oL2YCsQMlxMXF0TXXXEMff/yx/gwAoD5paWn07LPPig4QtxczgdiBEiB2ABqmRYudv72Pjo6mCRMm0BVXXEF33303BQUFmfKtvjO8/PLL1KtXL3rwwQepTZs21L9/fzp06JBl6pmRkUHTpk2jgQMH0qBBg8S2HDJkCGVmZurvsBYQu2NUVVXRggUL6K9//StdeumltGLFCsu1ET4GO3bsSA888IBoI5dddhktXLiQiouL9Xc0P6tXr6auXbvSxIkT6aqrrhKxdOlSqqkxfqugWbRosRcVFdHmzZvp4MGDFBYWRqNGjaK33nqL8vLU36/uDCx2Plh3795NWVlZ4kT0yCOPiIPZCtjE3q9fP/Ly8hInSz75vPnmm/o7rAXE7hi8Tz08PER74THXVq1aUUyMOT+eMQofg3/6059o3LhxYnx48eLFdOONN1qqA2QTO29DPll++umndMMNN5C/v/ppQJylRYu9urqaEhMTydvbm7Zt20b33HMPPffcc0KeVoLF3rt3b/Hv0tJS+uqrr2j48OHi6sIK2MTOPZHU1FTxHJ947rvvPvFvqwGxOwaL8vjx46Kd2MTOj60EH4PXXnstLVmyRDw+cOCAuIL8+eefqbJS/Y+RjGATe0REhHh8+vRp6tKlC/3666/isZVo0WLPzs6mqVOn0s0330xPPPEE9ejRw/JiLykpEZfFVhc7X/2MHDlS/NtqQOxNh6XIQy+DBw8WvWHu/LQEsfNVBl81Wlnshw8fhtg1lIs9KiqK+vTpQx999BFFRkbS/fffb1mxd+rUiZKTk0XdnnrqKXr44YfFxrcCNrHz9gsJCRFXQTwsw89ZEYi96eTn59MLL7wgrsB4uy1atMiyYm/btq0YSmW+/fZb6tu3rxC8VcawbWLfuXOnqBPfTtizZ0/y8/PT32EdWrTY+f5MluRdd91Fr7/+Ot1yyy2WFXvnzp3pscceo8mTJ4svJrdu3aq/2vzYxH799deL8f9HH31UnHgCAsyZnc5ZIPamU1FRIYb+7rzzTnHsTZo0ybJiv+SSS0QbfuWVV2jo0KE0e/ZscVVuFWxiHzNmjGjTPFTEJ0q+CrcaLVrs/AVGaGiokCSPyfEYIsuID2YrYRuK4Xpy8Je95eXWmcfEJnYeU1+7dq2oY3BwsPgOw4pwQ+JeE1+lgcbh4bW9e/eK/crjwvx9FI+7Wwk+BvlkzR00rueuXbssc0Vrwyb2lStXim3IxyBfEVkR9gt/qXvixAnTTzzKxd5SqD/GbkVsYq8/xg6AK+FjsP4YuxWxH2MH54DYLQrEDpobiL3l8ocVOwAAuCsQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQOwAAuBkQO7AcvFDCjh07LLeiEAAtBYgdNBtbtmwRyybynPMcCxcuFM/zOrRvvPEG/fDDD+KxWZSVldGqVavO5+fgJeDqL1tWWFhI77//vgjZcmb//ve/xUpIDM+b/9lnn9GcOXMoNjZWPGeDV8zhz8OfGQCzgdiBy+F1cefNm0dTp06l3377TSyhyMHrgPIq864SO0t7xowZNG7cuPN1ePfdd+nJJ588v64n/3/w4MHUrl07+uSTT8Rz9bnxxhvFIs8ML/YwduxYuvLKK+nrr7/+3fJnfBXCJzFe5B0As4HYgUspKioSK8mzPHkNV14j1wa/Vlxc7FKxc55XX31Vf4aooKCA7rjjDrF2JsNiHzVqlFidnwV/5MgR8bwNe7G/9NJL1K1bN/F8UFCQeJ6B2IErgdiBSzl79ixNmTJFDF/U1tbqz/6e5hQ7c+edd9LmzZvFv1nsjz/+OL333nt011130WuvvUZZWVniNcZe7FzWrFmzaMiQITR9+nRxomAgduBKIHbgMljkvr6+ogeckJCgP3shLHYeu2ZBPv3009SxY0dq27YtrVmzRn/HueEcfg+/1r59e/r73/9OYWFh508WAwcOFOPdw4YNowkTJlBUVJR4vj4ysfM4+m233UbHjh0Tj1nsDz/8sDjJrFu3jm666SYh/ZqaGvG6vdi5vsuWLRPv5bU4PT09RZ0gduBKIHbgMsrLy+m7774Tom0IFvuLL75II0eOJB8fH/Ecy5LHuXmoprq6mvz9/cX4PMPSHD9+PM2dO/f8uHavXr3oH//4xwVfYtbHNsbO9QkICBDx5ptv0jvvvHO+p11f7JmZmeJ7gUcffVRInIV9MbEznP/2228XZUDswJVA7MBlVFRU0PLly4WE+d8Xg8XOd6dwj9sGy7Fz58506NAh/Zlzd6Fs375dxKRJk+hf//rXeSH379+fli5dKv59MVjsPFzSo0cPGjNmDN16663iKqH+UEt9sTM8xs7vW7BgAZWWljYodj5R9OvXT5wsIHbgSiB24DJ4+IKHJkaPHk2RkZH6sxdysTF2HtpgsVdWVor/syR5vJ570Tx8wj3vvLw88d5Bgwadvw3xYtgPxfBVwCOPPEIbNmwQORh7sTOcd8CAAWK4hiV/MbEzixcvptatW4u6cB6IHbgCiB24lOjoaHrqqafo+++/15+5kMbEzrLlLzT5vnfuNTMzZ86kyZMnOyV2hnM+9NBD5088MrEnJSWJ2xq5l3///fc3KHbuqT/wwAPiTptnnnkGYgcuAWIHLoV/FMQ9Yu4Z//TTT+IWRxt+fn5i+KIxsWdkZNCDDz5ImzZtEs+HhoaKL2RZ9s6KncvmoaK3335bPJaJndmzZw916NBB1KkhsTNnzpyhTp06iXF/iB24AogduBweB9+1a5eQ4IgRI4SUOfjHQfwFZWNi5/F5Pinw+DX/3bRp08QXmjzO7qzYGR5H57FzPgFdTOz8RTCPs7dq1apRsTP891dddRXEDlwCxA6aBf5hEg9p8H3ttkhLSzv/Gt/OmJubKx7b4OER210vPARj+7vExERxMkhJSRF3zDAxMTHiDpqG4DF/zmPLa4Pzs6RZ6lwel29fF4ZPDJzf9hqfcLgetpNLfbi+4eHhv/tiFgCzgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMDNgNgBAMCtIPr/5N8BI6dSHTcAAAAASUVORK5CYII=","text/plain":["<IPython.core.display.Image object>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["### CIS 4120 NLP Fall 2023\n","### Assignment 4\n","\n","### In this assignment, we are going to build a text generation model (char-level) using the same data that we have used in the Session 22.\n","### You need to build a model following the given a set of conditions.\n","### NOTICE: Note that the goal of this assignment is to build a model which looks like the right-hand-side model in the image whereas we have built the left-hand-side model in the Session 22.\n","### You can always review the Session 22 contents and other materials from the internet sources, if needed, to work on the assignment 4.\n","\n","#connect Colab to your Google Drive.\n","from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')\n","\n","from IPython.display import Image\n","Image('/CIS 4120 - NLP/Assignment 4/different char rnn model.PNG')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3080,"status":"ok","timestamp":1702263063206,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"IgatqeTFeRBy"},"outputs":[],"source":["#Import the necessary libs which are already given to you.\n","import pandas as pd\n","import numpy as np\n","from string import punctuation\n","import urllib.request\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11258,"status":"ok","timestamp":1702263098069,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"SjCa_a3OWnS4"},"outputs":[],"source":["#load the data.\n","# http://www.gutenberg.org/files/11/11-0.txt\n","urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n","\n","f = open('11-0.txt', 'rb')\n","sentences = []\n","for sentence in f: # read line by line.\n","    sentence = sentence.strip() # remove \\r, \\n by using strip().\n","    sentence = sentence.lower() # lower-casing.\n","    sentence = sentence.decode('ascii', 'ignore') # remove such as \\xe2\\x80\\x99\n","    if len(sentence) > 0:\n","        sentences.append(sentence)\n","f.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1702263106373,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"eHdKoHG_NcnX","outputId":"606af828-5de3-493a-875a-3054a2b41744"},"outputs":[{"name":"stdout","output_type":"stream","text":["the project gutenberg ebook of alices adventures in wonderland, by lewis carroll\n","this ebook is for the use of anyone anywhere in the united states and\n","most other parts of the world at no cost and with almost no restrictions\n","whatsoever. you may copy it, give it away or re-use it under the terms\n","of the project gutenberg license included with this ebook or online at\n","['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll', 'this ebook is for the use of anyone anywhere in the united states and', 'most other parts of the world at no cost and with almost no restrictions', 'whatsoever. you may copy it, give it away or re-use it under the terms', 'of the project gutenberg license included with this ebook or online at']\n"]}],"source":["print (*sentences[:5], sep='\\n')\n","print (sentences[:5])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101,"status":"ok","timestamp":1702263108480,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"0C4AmuzENcpp","outputId":"434082a1-4652-4520-f1cc-3a8f1c34b306"},"outputs":[{"name":"stdout","output_type":"stream","text":["159484\n"]}],"source":["#put every element together.\n","total_data = ' '.join(sentences)\n","print(len(total_data))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1702263112164,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"L1W3smhDV_Ut","outputId":"0da436d0-7af3-467c-d68d-9dc458400796"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know. please, maam, is this new zealand or australia? (and she tried to curtsey as she spokefancy _curtseying_ as youre falling through the air! do you think you could manage it?) and what an ignorant little girl shell think me for asking! no, itll never do to ask: perhaps i shall see it written up somewhere. down, down, down. there was nothing else to do, so alice soon began talking again. dinahll miss me very much to-night, i should think! (dinah was the cat.) i hope theyll remember her saucer of milk at tea-time. dinah my dear! i wish you were down here with me! there are no mice in the air, im afraid, but you might catch a bat, and thats very like a mouse, you know. but do cats eat bats, i wonder? and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, do cats eat bats? do cats eat bats? and sometimes, do bats eat cats? for, you see, as she couldnt answer either question, it didnt much matter which way she put it. she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly, now, dinah, tell me the truth: did you ever eat a bat? when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over. alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it. there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner, oh my ears and whiskers, how late its getting! she was close behind it when she turned the corner, but the rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. there were doors all round the hall, but th'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["total_data[5000:7000]"]},{"cell_type":"markdown","metadata":{"id":"nvgQBeECSU4N"},"source":["## Start working on after this line:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yd3Q3kcWZOQt"},"outputs":[],"source":["######################### Start working on after this line:\n","######################### Start working on after this line:\n","######################### Start working on after this line:"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":117,"status":"ok","timestamp":1702263119257,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"VrI2DN7uWN_k"},"outputs":[],"source":["#take out a random sub-set of the text and save it to a new variable called raw_text.\n","# raw_text will be the data we will use for this assignment.\n","raw_text='''\n","it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know. please, maam, is this new zealand or australia? (and she tried to curtsey as she spokefancy _curtseying_ as youre falling through the air! do you think you could manage it?) and what an ignorant little girl shell think me for asking! no, itll never do to ask: perhaps i shall see it written up somewhere. down, down, down. there was nothing else to do, so alice soon began talking again. dinahll miss me very much to-night, i should think! (dinah was the cat.) i hope theyll remember her saucer of milk at tea-time. dinah my dear! i wish you were down here with me! there are no mice in the air, im afraid, but you might catch a bat, and thats very like a mouse, you know. but do cats eat bats, i wonder? and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, do cats eat bats? do cats eat bats? and sometimes, do bats eat cats? for, you see, as she couldnt answer either question, it didnt much matter which way she put it. she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly, now, dinah, tell me the truth: did you ever eat a bat? when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over. alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it. there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner, oh my ears and whiskers, how late its getting! she was close behind it when she turned the corner, but the rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. there were doors all round the hall\n","'''"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1702263125907,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"_-pF1R_-WXsS","outputId":"ff3f5fbc-af4b-450f-acf6-23e39601f825"},"outputs":[{"name":"stdout","output_type":"stream","text":["it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know. please, maam, is this new zealand or australia? (and she tried to curtsey as she spokefancy _curtseying_ as youre falling through the air! do you think you could manage it?) and what an ignorant little girl shell think me for asking! no, itll never do to ask: perhaps i shall see it written up somewhere. down, down, down. there was nothing else to do, so alice soon began talking again. dinahll miss me very much to-night, i should think! (dinah was the cat.) i hope theyll remember her saucer of milk at tea-time. dinah my dear! i wish you were down here with me! there are no mice in the air, im afraid, but you might catch a bat, and thats very like a mouse, you know. but do cats eat bats, i wonder? and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, do cats eat bats? do cats eat bats? and sometimes, do bats eat cats? for, you see, as she couldnt answer either question, it didnt much matter which way she put it. she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly, now, dinah, tell me the truth: did you ever eat a bat? when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over. alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it. there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner, oh my ears and whiskers, how late its getting! she was close behind it when she turned the corner, but the rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. there were doors all round the hall\n"]}],"source":["#remove unnecessary space such as newline break.\n","tokens = raw_text.split()\n","raw_text = ' '.join(tokens)\n","print(raw_text)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702263366937,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"7W4iV_E5Ncr0","outputId":"85534e17-c5e0-425a-d7a8-3423192adb39"},"outputs":[{"name":"stdout","output_type":"stream","text":["36\n","{' ': 0, '!': 1, '(': 2, ')': 3, ',': 4, '-': 5, '.': 6, ':': 7, ';': 8, '?': 9, '_': 10, 'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, 'z': 35}\n"]}],"source":["#generate a character (not vocab) set.\n","#YOUR CODE HERE:\n","\n","# All possible characters\n","char_vocab = sorted(list(set(raw_text)))\n","vocab_size = len(char_vocab)\n","print(vocab_size)\n","\n","# Character dictionary\n","char_dict = dict((char, index) for index, char in enumerate(char_vocab))\n","print(char_dict)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103,"status":"ok","timestamp":1702263383643,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"OzgxLUS-Nct5","outputId":"5510d405-f6e7-4102-d149-54bc0c72293d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: ' ', 1: '!', 2: '(', 3: ')', 4: ',', 5: '-', 6: '.', 7: ':', 8: ';', 9: '?', 10: '_', 11: 'a', 12: 'b', 13: 'c', 14: 'd', 15: 'e', 16: 'f', 17: 'g', 18: 'h', 19: 'i', 20: 'j', 21: 'k', 22: 'l', 23: 'm', 24: 'n', 25: 'o', 26: 'p', 27: 'q', 28: 'r', 29: 's', 30: 't', 31: 'u', 32: 'v', 33: 'w', 34: 'y', 35: 'z'}\n"]}],"source":["# assign an unique integer to each character.\n","#YOUR CODE HERE:\n","\n","# Switching key and value so the key is the numeric index\n","index_to_char = {}\n","for key, value in char_dict.items():\n","    index_to_char[value] = key\n","print(index_to_char)"]},{"cell_type":"markdown","metadata":{"id":"SDsBi8rBN3my"},"source":["## How to generate a data set for this task:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTNYL1nsNcyU"},"outputs":[],"source":["######################### how to generate a data set for character generation model:\n","# what we're trying to create is the below (just like the right-hand-side figure):\n","\n","# appl (input sequence) -> e (output sequence that needs to be predicted based on the input sequence)\n","#train_X = 'appl'\n","#train_y = 'e'"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":106,"status":"ok","timestamp":1702263423573,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"QsB_LreiNzsY"},"outputs":[],"source":["# We define the length of our input sequence as 10 & the length of our output sequence as 1\n","# -> total 11 length of input & output sequence length.\n","\n","seq_length = 10+1\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117,"status":"ok","timestamp":1702263432498,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"crZNxdSANzul","outputId":"dd84f939-f588-49c1-c72e-9d5705ce1152"},"outputs":[{"name":"stdout","output_type":"stream","text":["1980\n"]}],"source":["#iterate over the raw_text to generate consecutive sequence of 11 characters.\n","#The first 10 actual outputs are printed out below.\n","#The code is given for this part.\n","sequences = []\n","for i in range(seq_length, len(raw_text)):\n","  # 0:11, 1:12, 2:13\n","    seq = raw_text[i-seq_length:i]\n","    sequences.append(seq)\n","print( len(sequences))\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1702263451032,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"97sp2tjMNzxE","outputId":"fab96b77-799e-4d9d-93b9-0277bd4b0162"},"outputs":[{"data":{"text/plain":["['it didnt so',\n"," 't didnt sou',\n"," ' didnt soun',\n"," 'didnt sound',\n"," 'idnt sound ',\n"," 'dnt sound a',\n"," 'nt sound at',\n"," 't sound at ',\n"," ' sound at a',\n"," 'sound at al']"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["#note that every element list consists of 11 character length (including space).\n","sequences[:10]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702264400013,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"AU5ZRg0NNzzO","outputId":"4e7dafea-0d99-4dd1-f60b-afd2764a994f"},"outputs":[{"data":{"text/plain":["[[19, 30, 0, 14, 19, 14, 24, 30, 0, 29, 25],\n"," [30, 0, 14, 19, 14, 24, 30, 0, 29, 25, 31],\n"," [0, 14, 19, 14, 24, 30, 0, 29, 25, 31, 24],\n"," [14, 19, 14, 24, 30, 0, 29, 25, 31, 24, 14],\n"," [19, 14, 24, 30, 0, 29, 25, 31, 24, 14, 0],\n"," [14, 24, 30, 0, 29, 25, 31, 24, 14, 0, 11],\n"," [24, 30, 0, 29, 25, 31, 24, 14, 0, 11, 30],\n"," [30, 0, 29, 25, 31, 24, 14, 0, 11, 30, 0],\n"," [0, 29, 25, 31, 24, 14, 0, 11, 30, 0, 11],\n"," [29, 25, 31, 24, 14, 0, 11, 30, 0, 11, 22]]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# integer encoding using a character (not vocab) set.\n","#YOUR CODE HERE:\n","seq_encoded = [] # The whole data, Each entry: 10 for x + 1 for y\n","\n","for seq in sequences:\n","  # For each sequence: 'it didnt so'\n","  # Break it into characters: ['i', 't', ' ', 'd' . . . ]\n","  # Match it with the character dict where: {'character':index}\n","  curr_seq = [char_dict[char] for char in seq]\n","  seq_encoded.append(curr_seq)\n","\n","seq_encoded[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1701564333247,"user":{"displayName":"J “뉴욕외노자” KIM","userId":"00856370753399949288"},"user_tz":300},"id":"drQVBUGCXMpK","outputId":"5f5a50e1-9fd4-48f5-82fd-97b20680ce47"},"outputs":[{"data":{"text/plain":["[[38, 49, 0, 33, 38, 33, 43, 49, 0, 48, 44],\n"," [49, 0, 33, 38, 33, 43, 49, 0, 48, 44, 50],\n"," [0, 33, 38, 33, 43, 49, 0, 48, 44, 50, 43],\n"," [33, 38, 33, 43, 49, 0, 48, 44, 50, 43, 33],\n"," [38, 33, 43, 49, 0, 48, 44, 50, 43, 33, 0],\n"," [33, 43, 49, 0, 48, 44, 50, 43, 33, 0, 30],\n"," [43, 49, 0, 48, 44, 50, 43, 33, 0, 30, 49],\n"," [49, 0, 48, 44, 50, 43, 33, 0, 30, 49, 0],\n"," [0, 48, 44, 50, 43, 33, 0, 30, 49, 0, 30],\n"," [48, 44, 50, 43, 33, 0, 30, 49, 0, 30, 41]]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# If you print out the first 10 elements, the output should look like below.\n","# Note that these outputs correspond to the above \"sequences[:10]\"\n","encoded_sequences[:10]"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":107,"status":"ok","timestamp":1702267703951,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"cC1GFoD3W1aX"},"outputs":[],"source":["encoded_sequences = np.array(encoded_sequences)\n","\n","# assign all the integer elements (except for the last integer element) to X_data.\n","X_data = [sublist[:10] for sublist in seq_encoded]\n","# assign the last integer element to y_data (which will be used as the output values for the corresponding input values).\n","y_data = [sublist_y[-1] for sublist_y in seq_encoded]"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101,"status":"ok","timestamp":1702267710775,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"DHdb3JZT34CG","outputId":"d2a9ebbc-a0da-4b48-f82b-0491a8df01bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["1980\n","10\n","1980\n","25\n"]}],"source":["print(len(X_data))\n","print(len(X_data[0]))\n","print(len(y_data))\n","print(y_data[0])"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1702267783643,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"bboiI8jFDtwv","outputId":"61ed2c39-fe73-4f20-edd3-e943a60c706a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[19, 30, 0, 14, 19, 14, 24, 30, 0, 29, 25]\n","[19, 30, 0, 14, 19, 14, 24, 30, 0, 29]\n","25\n"]}],"source":["print(seq_encoded[0])\n","print(seq_encoded[0][0:10])\n","print(seq_encoded[0][10])"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1702267797469,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"8ScvHutD3u_5","outputId":"add19f8c-20b0-4128-d529-2313a47918b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[19, 30, 0, 14, 19, 14, 24, 30, 0, 29], [30, 0, 14, 19, 14, 24, 30, 0, 29, 25], [0, 14, 19, 14, 24, 30, 0, 29, 25, 31], [14, 19, 14, 24, 30, 0, 29, 25, 31, 24], [19, 14, 24, 30, 0, 29, 25, 31, 24, 14]]\n","[25, 31, 24, 14, 0]\n"]}],"source":["# My test print\n","print(X_data[:5])\n","print(y_data[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701564333699,"user":{"displayName":"J “뉴욕외노자” KIM","userId":"00856370753399949288"},"user_tz":300},"id":"eJTT-seAYZZY","outputId":"d3b4fcf9-52af-4131-8215-5f068cda0bcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[38 49  0 33 38 33 43 49  0 48]\n"," [49  0 33 38 33 43 49  0 48 44]\n"," [ 0 33 38 33 43 49  0 48 44 50]\n"," [33 38 33 43 49  0 48 44 50 43]\n"," [38 33 43 49  0 48 44 50 43 33]]\n","[44 50 43 33  0]\n"]}],"source":["# If you print out the first 5 X and y samples, the output should look like below.\n","print(X_data[:5])\n","print(y_data[:5])\n"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1702267882644,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"s3sH4Tl0YZbk","outputId":"d0283725-8d51-40ff-e96e-93c58ae084e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1980, 10, 36)\n","(1980, 36)\n"]}],"source":["#one-hot encoding.\n","#The code is given for this part.\n","X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n","X_data_one_hot = np.array(X_data_one_hot)\n","y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)\n","\n","print(X_data_one_hot.shape)\n","print(y_data_one_hot.shape)"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":133,"status":"ok","timestamp":1702264822539,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"_I4deO_UV9ea"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43772,"status":"ok","timestamp":1702270443665,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"q-dNKEivNz1Y","outputId":"545a9d64-133a-4a69-a8b8-2479cdf81a82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","62/62 - 2s - loss: 3.2372 - accuracy: 0.1783 - 2s/epoch - 27ms/step\n","Epoch 2/150\n","62/62 - 0s - loss: 2.9118 - accuracy: 0.1990 - 261ms/epoch - 4ms/step\n","Epoch 3/150\n","62/62 - 0s - loss: 2.8842 - accuracy: 0.1990 - 251ms/epoch - 4ms/step\n","Epoch 4/150\n","62/62 - 0s - loss: 2.8493 - accuracy: 0.1990 - 261ms/epoch - 4ms/step\n","Epoch 5/150\n","62/62 - 0s - loss: 2.8072 - accuracy: 0.2030 - 250ms/epoch - 4ms/step\n","Epoch 6/150\n","62/62 - 0s - loss: 2.7512 - accuracy: 0.2126 - 255ms/epoch - 4ms/step\n","Epoch 7/150\n","62/62 - 0s - loss: 2.6823 - accuracy: 0.2556 - 266ms/epoch - 4ms/step\n","Epoch 8/150\n","62/62 - 0s - loss: 2.6066 - accuracy: 0.2874 - 261ms/epoch - 4ms/step\n","Epoch 9/150\n","62/62 - 0s - loss: 2.5418 - accuracy: 0.3232 - 244ms/epoch - 4ms/step\n","Epoch 10/150\n","62/62 - 0s - loss: 2.4757 - accuracy: 0.3222 - 296ms/epoch - 5ms/step\n","Epoch 11/150\n","62/62 - 0s - loss: 2.4287 - accuracy: 0.3389 - 354ms/epoch - 6ms/step\n","Epoch 12/150\n","62/62 - 0s - loss: 2.3779 - accuracy: 0.3384 - 329ms/epoch - 5ms/step\n","Epoch 13/150\n","62/62 - 0s - loss: 2.3370 - accuracy: 0.3611 - 338ms/epoch - 5ms/step\n","Epoch 14/150\n","62/62 - 0s - loss: 2.2979 - accuracy: 0.3621 - 320ms/epoch - 5ms/step\n","Epoch 15/150\n","62/62 - 0s - loss: 2.2608 - accuracy: 0.3707 - 333ms/epoch - 5ms/step\n","Epoch 16/150\n","62/62 - 0s - loss: 2.2332 - accuracy: 0.3788 - 329ms/epoch - 5ms/step\n","Epoch 17/150\n","62/62 - 0s - loss: 2.1959 - accuracy: 0.3808 - 354ms/epoch - 6ms/step\n","Epoch 18/150\n","62/62 - 0s - loss: 2.1692 - accuracy: 0.3823 - 330ms/epoch - 5ms/step\n","Epoch 19/150\n","62/62 - 0s - loss: 2.1393 - accuracy: 0.3894 - 345ms/epoch - 6ms/step\n","Epoch 20/150\n","62/62 - 0s - loss: 2.1175 - accuracy: 0.3934 - 345ms/epoch - 6ms/step\n","Epoch 21/150\n","62/62 - 0s - loss: 2.0848 - accuracy: 0.4066 - 343ms/epoch - 6ms/step\n","Epoch 22/150\n","62/62 - 0s - loss: 2.0635 - accuracy: 0.4116 - 326ms/epoch - 5ms/step\n","Epoch 23/150\n","62/62 - 0s - loss: 2.0336 - accuracy: 0.4136 - 265ms/epoch - 4ms/step\n","Epoch 24/150\n","62/62 - 0s - loss: 2.0088 - accuracy: 0.4162 - 257ms/epoch - 4ms/step\n","Epoch 25/150\n","62/62 - 0s - loss: 1.9855 - accuracy: 0.4237 - 250ms/epoch - 4ms/step\n","Epoch 26/150\n","62/62 - 0s - loss: 1.9611 - accuracy: 0.4303 - 264ms/epoch - 4ms/step\n","Epoch 27/150\n","62/62 - 0s - loss: 1.9381 - accuracy: 0.4364 - 257ms/epoch - 4ms/step\n","Epoch 28/150\n","62/62 - 0s - loss: 1.9013 - accuracy: 0.4525 - 247ms/epoch - 4ms/step\n","Epoch 29/150\n","62/62 - 0s - loss: 1.8727 - accuracy: 0.4576 - 255ms/epoch - 4ms/step\n","Epoch 30/150\n","62/62 - 0s - loss: 1.8458 - accuracy: 0.4606 - 245ms/epoch - 4ms/step\n","Epoch 31/150\n","62/62 - 0s - loss: 1.8251 - accuracy: 0.4672 - 258ms/epoch - 4ms/step\n","Epoch 32/150\n","62/62 - 0s - loss: 1.7979 - accuracy: 0.4788 - 246ms/epoch - 4ms/step\n","Epoch 33/150\n","62/62 - 0s - loss: 1.7628 - accuracy: 0.4848 - 241ms/epoch - 4ms/step\n","Epoch 34/150\n","62/62 - 0s - loss: 1.7282 - accuracy: 0.4914 - 246ms/epoch - 4ms/step\n","Epoch 35/150\n","62/62 - 0s - loss: 1.6948 - accuracy: 0.5076 - 259ms/epoch - 4ms/step\n","Epoch 36/150\n","62/62 - 0s - loss: 1.6713 - accuracy: 0.5091 - 254ms/epoch - 4ms/step\n","Epoch 37/150\n","62/62 - 0s - loss: 1.6351 - accuracy: 0.5126 - 270ms/epoch - 4ms/step\n","Epoch 38/150\n","62/62 - 0s - loss: 1.6028 - accuracy: 0.5288 - 265ms/epoch - 4ms/step\n","Epoch 39/150\n","62/62 - 0s - loss: 1.5728 - accuracy: 0.5348 - 302ms/epoch - 5ms/step\n","Epoch 40/150\n","62/62 - 0s - loss: 1.5423 - accuracy: 0.5419 - 265ms/epoch - 4ms/step\n","Epoch 41/150\n","62/62 - 0s - loss: 1.5113 - accuracy: 0.5525 - 260ms/epoch - 4ms/step\n","Epoch 42/150\n","62/62 - 0s - loss: 1.4673 - accuracy: 0.5707 - 255ms/epoch - 4ms/step\n","Epoch 43/150\n","62/62 - 0s - loss: 1.4364 - accuracy: 0.5773 - 259ms/epoch - 4ms/step\n","Epoch 44/150\n","62/62 - 0s - loss: 1.3971 - accuracy: 0.5773 - 277ms/epoch - 4ms/step\n","Epoch 45/150\n","62/62 - 0s - loss: 1.3673 - accuracy: 0.5995 - 258ms/epoch - 4ms/step\n","Epoch 46/150\n","62/62 - 0s - loss: 1.3304 - accuracy: 0.6167 - 275ms/epoch - 4ms/step\n","Epoch 47/150\n","62/62 - 0s - loss: 1.3022 - accuracy: 0.6263 - 241ms/epoch - 4ms/step\n","Epoch 48/150\n","62/62 - 0s - loss: 1.2643 - accuracy: 0.6333 - 261ms/epoch - 4ms/step\n","Epoch 49/150\n","62/62 - 0s - loss: 1.2238 - accuracy: 0.6485 - 244ms/epoch - 4ms/step\n","Epoch 50/150\n","62/62 - 0s - loss: 1.2007 - accuracy: 0.6520 - 270ms/epoch - 4ms/step\n","Epoch 51/150\n","62/62 - 0s - loss: 1.1608 - accuracy: 0.6616 - 243ms/epoch - 4ms/step\n","Epoch 52/150\n","62/62 - 0s - loss: 1.1300 - accuracy: 0.6798 - 244ms/epoch - 4ms/step\n","Epoch 53/150\n","62/62 - 0s - loss: 1.0906 - accuracy: 0.6985 - 256ms/epoch - 4ms/step\n","Epoch 54/150\n","62/62 - 0s - loss: 1.0600 - accuracy: 0.7081 - 266ms/epoch - 4ms/step\n","Epoch 55/150\n","62/62 - 0s - loss: 1.0246 - accuracy: 0.7187 - 260ms/epoch - 4ms/step\n","Epoch 56/150\n","62/62 - 0s - loss: 0.9898 - accuracy: 0.7384 - 255ms/epoch - 4ms/step\n","Epoch 57/150\n","62/62 - 0s - loss: 0.9593 - accuracy: 0.7359 - 242ms/epoch - 4ms/step\n","Epoch 58/150\n","62/62 - 0s - loss: 0.9357 - accuracy: 0.7465 - 262ms/epoch - 4ms/step\n","Epoch 59/150\n","62/62 - 0s - loss: 0.8988 - accuracy: 0.7616 - 267ms/epoch - 4ms/step\n","Epoch 60/150\n","62/62 - 0s - loss: 0.8667 - accuracy: 0.7758 - 295ms/epoch - 5ms/step\n","Epoch 61/150\n","62/62 - 0s - loss: 0.8360 - accuracy: 0.7828 - 329ms/epoch - 5ms/step\n","Epoch 62/150\n","62/62 - 0s - loss: 0.8111 - accuracy: 0.7990 - 326ms/epoch - 5ms/step\n","Epoch 63/150\n","62/62 - 0s - loss: 0.7860 - accuracy: 0.8035 - 327ms/epoch - 5ms/step\n","Epoch 64/150\n","62/62 - 0s - loss: 0.7491 - accuracy: 0.8227 - 352ms/epoch - 6ms/step\n","Epoch 65/150\n","62/62 - 0s - loss: 0.7290 - accuracy: 0.8308 - 347ms/epoch - 6ms/step\n","Epoch 66/150\n","62/62 - 0s - loss: 0.6963 - accuracy: 0.8374 - 338ms/epoch - 5ms/step\n","Epoch 67/150\n","62/62 - 0s - loss: 0.6701 - accuracy: 0.8495 - 327ms/epoch - 5ms/step\n","Epoch 68/150\n","62/62 - 0s - loss: 0.6450 - accuracy: 0.8525 - 341ms/epoch - 6ms/step\n","Epoch 69/150\n","62/62 - 0s - loss: 0.6211 - accuracy: 0.8707 - 335ms/epoch - 5ms/step\n","Epoch 70/150\n","62/62 - 0s - loss: 0.5931 - accuracy: 0.8763 - 333ms/epoch - 5ms/step\n","Epoch 71/150\n","62/62 - 0s - loss: 0.5720 - accuracy: 0.8869 - 370ms/epoch - 6ms/step\n","Epoch 72/150\n","62/62 - 0s - loss: 0.5512 - accuracy: 0.8919 - 302ms/epoch - 5ms/step\n","Epoch 73/150\n","62/62 - 0s - loss: 0.5225 - accuracy: 0.9020 - 268ms/epoch - 4ms/step\n","Epoch 74/150\n","62/62 - 0s - loss: 0.4966 - accuracy: 0.9111 - 273ms/epoch - 4ms/step\n","Epoch 75/150\n","62/62 - 0s - loss: 0.4779 - accuracy: 0.9131 - 262ms/epoch - 4ms/step\n","Epoch 76/150\n","62/62 - 0s - loss: 0.4617 - accuracy: 0.9197 - 263ms/epoch - 4ms/step\n","Epoch 77/150\n","62/62 - 0s - loss: 0.4451 - accuracy: 0.9202 - 253ms/epoch - 4ms/step\n","Epoch 78/150\n","62/62 - 0s - loss: 0.4180 - accuracy: 0.9328 - 264ms/epoch - 4ms/step\n","Epoch 79/150\n","62/62 - 0s - loss: 0.4029 - accuracy: 0.9369 - 255ms/epoch - 4ms/step\n","Epoch 80/150\n","62/62 - 0s - loss: 0.3890 - accuracy: 0.9424 - 259ms/epoch - 4ms/step\n","Epoch 81/150\n","62/62 - 0s - loss: 0.3693 - accuracy: 0.9434 - 266ms/epoch - 4ms/step\n","Epoch 82/150\n","62/62 - 0s - loss: 0.3495 - accuracy: 0.9530 - 273ms/epoch - 4ms/step\n","Epoch 83/150\n","62/62 - 0s - loss: 0.3352 - accuracy: 0.9551 - 253ms/epoch - 4ms/step\n","Epoch 84/150\n","62/62 - 0s - loss: 0.3237 - accuracy: 0.9535 - 247ms/epoch - 4ms/step\n","Epoch 85/150\n","62/62 - 0s - loss: 0.3048 - accuracy: 0.9611 - 264ms/epoch - 4ms/step\n","Epoch 86/150\n","62/62 - 0s - loss: 0.2964 - accuracy: 0.9621 - 263ms/epoch - 4ms/step\n","Epoch 87/150\n","62/62 - 0s - loss: 0.2807 - accuracy: 0.9667 - 265ms/epoch - 4ms/step\n","Epoch 88/150\n","62/62 - 0s - loss: 0.2671 - accuracy: 0.9677 - 266ms/epoch - 4ms/step\n","Epoch 89/150\n","62/62 - 0s - loss: 0.2567 - accuracy: 0.9747 - 232ms/epoch - 4ms/step\n","Epoch 90/150\n","62/62 - 0s - loss: 0.2418 - accuracy: 0.9758 - 260ms/epoch - 4ms/step\n","Epoch 91/150\n","62/62 - 0s - loss: 0.2285 - accuracy: 0.9763 - 260ms/epoch - 4ms/step\n","Epoch 92/150\n","62/62 - 0s - loss: 0.2240 - accuracy: 0.9722 - 253ms/epoch - 4ms/step\n","Epoch 93/150\n","62/62 - 0s - loss: 0.2134 - accuracy: 0.9803 - 265ms/epoch - 4ms/step\n","Epoch 94/150\n","62/62 - 0s - loss: 0.2047 - accuracy: 0.9828 - 256ms/epoch - 4ms/step\n","Epoch 95/150\n","62/62 - 0s - loss: 0.1945 - accuracy: 0.9838 - 249ms/epoch - 4ms/step\n","Epoch 96/150\n","62/62 - 0s - loss: 0.1816 - accuracy: 0.9864 - 257ms/epoch - 4ms/step\n","Epoch 97/150\n","62/62 - 0s - loss: 0.1733 - accuracy: 0.9838 - 252ms/epoch - 4ms/step\n","Epoch 98/150\n","62/62 - 0s - loss: 0.1668 - accuracy: 0.9859 - 255ms/epoch - 4ms/step\n","Epoch 99/150\n","62/62 - 0s - loss: 0.1588 - accuracy: 0.9869 - 247ms/epoch - 4ms/step\n","Epoch 100/150\n","62/62 - 0s - loss: 0.1521 - accuracy: 0.9874 - 252ms/epoch - 4ms/step\n","Epoch 101/150\n","62/62 - 0s - loss: 0.1535 - accuracy: 0.9869 - 244ms/epoch - 4ms/step\n","Epoch 102/150\n","62/62 - 0s - loss: 0.1423 - accuracy: 0.9874 - 260ms/epoch - 4ms/step\n","Epoch 103/150\n","62/62 - 0s - loss: 0.1357 - accuracy: 0.9879 - 249ms/epoch - 4ms/step\n","Epoch 104/150\n","62/62 - 0s - loss: 0.1321 - accuracy: 0.9889 - 264ms/epoch - 4ms/step\n","Epoch 105/150\n","62/62 - 0s - loss: 0.1251 - accuracy: 0.9899 - 253ms/epoch - 4ms/step\n","Epoch 106/150\n","62/62 - 0s - loss: 0.1194 - accuracy: 0.9889 - 244ms/epoch - 4ms/step\n","Epoch 107/150\n","62/62 - 0s - loss: 0.1094 - accuracy: 0.9924 - 259ms/epoch - 4ms/step\n","Epoch 108/150\n","62/62 - 0s - loss: 0.1100 - accuracy: 0.9909 - 263ms/epoch - 4ms/step\n","Epoch 109/150\n","62/62 - 0s - loss: 0.1101 - accuracy: 0.9904 - 276ms/epoch - 4ms/step\n","Epoch 110/150\n","62/62 - 0s - loss: 0.0993 - accuracy: 0.9919 - 299ms/epoch - 5ms/step\n","Epoch 111/150\n","62/62 - 0s - loss: 0.1052 - accuracy: 0.9894 - 360ms/epoch - 6ms/step\n","Epoch 112/150\n","62/62 - 0s - loss: 0.0967 - accuracy: 0.9919 - 338ms/epoch - 5ms/step\n","Epoch 113/150\n","62/62 - 0s - loss: 0.0908 - accuracy: 0.9904 - 334ms/epoch - 5ms/step\n","Epoch 114/150\n","62/62 - 0s - loss: 0.0885 - accuracy: 0.9924 - 342ms/epoch - 6ms/step\n","Epoch 115/150\n","62/62 - 0s - loss: 0.0842 - accuracy: 0.9919 - 327ms/epoch - 5ms/step\n","Epoch 116/150\n","62/62 - 0s - loss: 0.0826 - accuracy: 0.9904 - 317ms/epoch - 5ms/step\n","Epoch 117/150\n","62/62 - 0s - loss: 0.0781 - accuracy: 0.9909 - 331ms/epoch - 5ms/step\n","Epoch 118/150\n","62/62 - 0s - loss: 0.0746 - accuracy: 0.9929 - 339ms/epoch - 5ms/step\n","Epoch 119/150\n","62/62 - 0s - loss: 0.0696 - accuracy: 0.9919 - 345ms/epoch - 6ms/step\n","Epoch 120/150\n","62/62 - 0s - loss: 0.0685 - accuracy: 0.9909 - 315ms/epoch - 5ms/step\n","Epoch 121/150\n","62/62 - 0s - loss: 0.0652 - accuracy: 0.9924 - 336ms/epoch - 5ms/step\n","Epoch 122/150\n","62/62 - 0s - loss: 0.0660 - accuracy: 0.9894 - 329ms/epoch - 5ms/step\n","Epoch 123/150\n","62/62 - 0s - loss: 0.0644 - accuracy: 0.9919 - 252ms/epoch - 4ms/step\n","Epoch 124/150\n","62/62 - 0s - loss: 0.0634 - accuracy: 0.9909 - 246ms/epoch - 4ms/step\n","Epoch 125/150\n","62/62 - 0s - loss: 0.0602 - accuracy: 0.9929 - 249ms/epoch - 4ms/step\n","Epoch 126/150\n","62/62 - 0s - loss: 0.0578 - accuracy: 0.9914 - 244ms/epoch - 4ms/step\n","Epoch 127/150\n","62/62 - 0s - loss: 0.0580 - accuracy: 0.9929 - 255ms/epoch - 4ms/step\n","Epoch 128/150\n","62/62 - 0s - loss: 0.0567 - accuracy: 0.9899 - 240ms/epoch - 4ms/step\n","Epoch 129/150\n","62/62 - 0s - loss: 0.0516 - accuracy: 0.9914 - 264ms/epoch - 4ms/step\n","Epoch 130/150\n","62/62 - 0s - loss: 0.0520 - accuracy: 0.9909 - 241ms/epoch - 4ms/step\n","Epoch 131/150\n","62/62 - 0s - loss: 0.0498 - accuracy: 0.9929 - 257ms/epoch - 4ms/step\n","Epoch 132/150\n","62/62 - 0s - loss: 0.0492 - accuracy: 0.9924 - 250ms/epoch - 4ms/step\n","Epoch 133/150\n","62/62 - 0s - loss: 0.0480 - accuracy: 0.9914 - 268ms/epoch - 4ms/step\n","Epoch 134/150\n","62/62 - 0s - loss: 0.0490 - accuracy: 0.9914 - 251ms/epoch - 4ms/step\n","Epoch 135/150\n","62/62 - 0s - loss: 0.0446 - accuracy: 0.9924 - 265ms/epoch - 4ms/step\n","Epoch 136/150\n","62/62 - 0s - loss: 0.0434 - accuracy: 0.9924 - 253ms/epoch - 4ms/step\n","Epoch 137/150\n","62/62 - 0s - loss: 0.0741 - accuracy: 0.9833 - 259ms/epoch - 4ms/step\n","Epoch 138/150\n","62/62 - 0s - loss: 0.0837 - accuracy: 0.9854 - 257ms/epoch - 4ms/step\n","Epoch 139/150\n","62/62 - 0s - loss: 0.0703 - accuracy: 0.9879 - 244ms/epoch - 4ms/step\n","Epoch 140/150\n","62/62 - 0s - loss: 0.0818 - accuracy: 0.9869 - 257ms/epoch - 4ms/step\n","Epoch 141/150\n","62/62 - 0s - loss: 0.0663 - accuracy: 0.9894 - 279ms/epoch - 5ms/step\n","Epoch 142/150\n","62/62 - 0s - loss: 0.0558 - accuracy: 0.9909 - 259ms/epoch - 4ms/step\n","Epoch 143/150\n","62/62 - 0s - loss: 0.0400 - accuracy: 0.9919 - 263ms/epoch - 4ms/step\n","Epoch 144/150\n","62/62 - 0s - loss: 0.0353 - accuracy: 0.9919 - 259ms/epoch - 4ms/step\n","Epoch 145/150\n","62/62 - 0s - loss: 0.0345 - accuracy: 0.9919 - 255ms/epoch - 4ms/step\n","Epoch 146/150\n","62/62 - 0s - loss: 0.0329 - accuracy: 0.9914 - 246ms/epoch - 4ms/step\n","Epoch 147/150\n","62/62 - 0s - loss: 0.0314 - accuracy: 0.9939 - 246ms/epoch - 4ms/step\n","Epoch 148/150\n","62/62 - 0s - loss: 0.0328 - accuracy: 0.9924 - 257ms/epoch - 4ms/step\n","Epoch 149/150\n","62/62 - 0s - loss: 0.0334 - accuracy: 0.9919 - 272ms/epoch - 4ms/step\n","Epoch 150/150\n","62/62 - 0s - loss: 0.0299 - accuracy: 0.9934 - 248ms/epoch - 4ms/step\n"]}],"source":["# Build a RNN model.\n","# Below are the parameter values that are given to you.\n","hidden_units = 64\n","\n","# In the given RNN model, you should define the last dense output layer:\n","\n","model = Sequential()\n","# https://stackoverflow.com/questions/55296013/why-set-return-sequences-true-and-stateful-true-for-tf-keras-layers-lstm\n","# return_sequences = True --> Produces output for each step instead of only output for last step\n","# stateful = True --> no refreshing LSTM internals after each batch, maintains continuity\n","model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n","# model.add(LSTM(hidden_units))\n","model.add(Dense(vocab_size, activation = 'softmax'))\n","\n","# use 'adam' optimizer for the optimization algorithm, choose a proper loss function for this model, calculate accuracy to check the performance of the model.\n","# choose 150 for the number of epochs.\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","history = model.fit(X_data_one_hot, y_data_one_hot, epochs = 150, verbose = 2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFsgdu3tNz8H"},"outputs":[],"source":["######################### The next step is to generate a sentence after seeding the initial texts.\n","######################### e.g. When initiating the below seed_text, your trained model will predict the next n number of characters.\n","######################### Due to the complexity of the codes, this part is given to you."]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":117,"status":"ok","timestamp":1702268209413,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"Me2ixkD6Nc0e"},"outputs":[],"source":["seed_text='it didnt so'\n","\n","# initial sequence (seed_text) to start with:\n","init_text = seed_text\n","sentence = ''\n"]},{"cell_type":"code","execution_count":136,"metadata":{"executionInfo":{"elapsed":2305,"status":"ok","timestamp":1702270626293,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"Jm-qSjHfHJ87"},"outputs":[],"source":["# predicting next n characters:\n","n=50\n","for _ in range(n):\n","    #integer encoding for the initial sequence.\n","    encoded = [char_dict[char] for char in seed_text]\n","    #zero-padding for the integer-encoded data.\n","    encoded = pad_sequences([encoded], maxlen=seq_length-1, padding='pre')\n","    encoded = to_categorical(encoded, num_classes=len(char_dict))\n","    # predicting next character based on the seed_text and deriving the index of highest character among 56 characters.\n","    result = model.predict(encoded, verbose=0)\n","    result = np.argmax(result, axis=1)\n","\n","    for char, index in char_dict.items():\n","        if index == result:\n","            break\n","    # initial sequence (seed_text) + predicted character.\n","    seed_text = seed_text + char\n","    # add predicted character to the sentence.\n","    sentence = sentence + char\n","#return the final sentence.\n","sentence = init_text + sentence\n"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1702270569126,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"aVs7s6rNKeJz","outputId":"6b438f75-b51a-4a8b-d110-554f27ccd24b"},"outputs":[{"name":"stdout","output_type":"stream","text":["it didnt sound at all the right word) but i shall have to ask\n"]}],"source":["######################### YOU SHOULD PRINT OUT THE FINAL OUTPUT, sentence variable, TO SHOW YOUR PREDICTED SENTENCE.\n","\n","# predicted sentence:\n","print(sentence)\n","\n","# It is missing a good number of words\n","# Input: 'it didnt so'\n","#   Length: 11\n","# Output (past the input): 'und at all the right word) but i shall have to ask\n","#   Length: 50\n","\n","# original sentence:\n","# it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zs8udOgYPvRs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":140,"metadata":{"executionInfo":{"elapsed":4137,"status":"ok","timestamp":1702270763877,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"pvvCei5ZVNRz"},"outputs":[],"source":["# Trying with longer prediction\n","\n","sentence2 = ''\n","for _ in range(100):\n","    #integer encoding for the initial sequence.\n","    encoded = [char_dict[char] for char in seed_text]\n","    #zero-padding for the integer-encoded data.\n","    encoded = pad_sequences([encoded], maxlen=seq_length-1, padding='pre')\n","    encoded = to_categorical(encoded, num_classes=len(char_dict))\n","    # predicting next character based on the seed_text and deriving the index of highest character among 56 characters.\n","    result = model.predict(encoded, verbose=0)\n","    result = np.argmax(result, axis=1)\n","\n","    for char, index in char_dict.items():\n","        if index == result:\n","            break\n","    # initial sequence (seed_text) + predicted character.\n","    seed_text = seed_text + char\n","    # add predicted character to the sentence2.\n","    sentence2 = sentence2 + char\n","#return the final sentence2.\n","sentence2 = init_text + sentence2"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1702270765071,"user":{"displayName":"Tyler Yang","userId":"16925440138058434007"},"user_tz":300},"id":"U-5N7D9wPcVB","outputId":"0a54b4c1-79b8-4280-e945-faffa9697fdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["it didnt soey as she spokefancy _curtseying_ as youre falling through the air! do you think you could manage it\n","\n","it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know.\n"]}],"source":["print(sentence2)\n","print()\n","# original sentence:\n","# it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know.\n","print('it didnt sound at all the right word) but i shall have to ask them what the name of the country is, you know.')\n","\n","# Increasing the length of the prediction seems to make it worse"]}],"metadata":{"colab":{"provenance":[{"file_id":"1wx9-Uhn4nU_GLlbZfr9dbDPA68nkDeWR","timestamp":1701566592962},{"file_id":"1_7vBRppBWZlD8PMv_izSUkjxEENfYMMR","timestamp":1701476790813},{"file_id":"1OaA5AIEvns4OiZMcKoqxF_VreiWlim9y","timestamp":1699210252409},{"file_id":"1hbJ5G649MW3M8dsZqJNCYwRqe9KbMwPj","timestamp":1699201130322},{"file_id":"1GCwe9IREgVD2fA0c4lUwxxgBEDx9b-RL","timestamp":1698613894958},{"file_id":"1ko6I7hjwVy-bqfPwAblEnuP5o3q_bgSV","timestamp":1698256003727},{"file_id":"1HBbdfpemxsD83y6OCXtCEl25Tsb3EgKX","timestamp":1696094358527}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
